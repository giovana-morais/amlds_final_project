{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfec7aa-f386-422e-a965-3f15aa2e3128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:18:27.276920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747106307.328215  188854 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747106307.344921  188854 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747106307.459602  188854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747106307.459617  188854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747106307.459619  188854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747106307.459620  188854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neural_tangents as nt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, jit, jacfwd, jacrev, lax, random, vmap\n",
    "from jax.example_libraries import optimizers\n",
    "from neural_tangents import stax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c67464-d868-4ace-bfc2-fc6c52de9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps.get_cmap('tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cfc9299-fb90-43b4-97e4-2c24b36bcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3(a) and 3(b). Sweep over alpha and epsilon.\n",
    "def phi(z, eps = 0.25):\n",
    "    return z + 0.5*eps*z**2\n",
    "\n",
    "def NN_func2(params, X, alpha, eps=0.25):\n",
    "    a, W = params\n",
    "\n",
    "    D = W.shape[1]\n",
    "    N = a.shape[0]\n",
    "\n",
    "    h = W @ X / jnp.sqrt(D)\n",
    "    f = alpha * jnp.mean( phi(h, eps = eps), axis = 0)\n",
    "    return f\n",
    "\n",
    "def target_fn(beta, X):\n",
    "    return (X.T @ beta / jnp.sqrt(D))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f50266aa-de51-4bcc-8991-3b492d4476b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius(x):\n",
    "    eigenval, eigenvec = jax.numpy.linalg.eigh(x)\n",
    "    frobenius_norm = jnp.sqrt(np.sum(eigenval**2))\n",
    "    return frobenius_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00064ad-ea80-4448-9fc5-8a0af73c957e",
   "metadata": {},
   "source": [
    "# Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "204ad158-b192-42e1-8e92-529a1589e2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 550), (100, 1000))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49203609-ecd4-4a52-8258-b0028b47ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.03125\n",
      " \n",
      "  t: 4900 | train loss: 2.2580341465072706e-05 | test loss: 0.0009616861934773624 |frob ||kt-k0||_2: 0.0030914403032511473"
     ]
    }
   ],
   "source": [
    "D = 100\n",
    "P = 550\n",
    "N = 500\n",
    "ntk_interval = 100 \n",
    "\n",
    "X = random.normal(random.PRNGKey(0), (D,P))\n",
    "Xt = random.normal(random.PRNGKey(1), (D,1000))\n",
    "beta = random.normal(random.PRNGKey(2), (D,))\n",
    "\n",
    "y = target_fn(beta, X)\n",
    "yt = target_fn(beta, Xt)\n",
    "\n",
    "a = random.normal(random.PRNGKey(0), (N, ))\n",
    "W = random.normal(random.PRNGKey(0), (N, D))\n",
    "params = [a, W]\n",
    "\n",
    "eps = 0.25\n",
    "eta = 0.5 * N\n",
    "lamb = 0.0\n",
    "opt_init, opt_update, get_params = optimizers.sgd(eta)\n",
    "\n",
    "alphas = [2**(-5),0.25,0.5,1.0,2.0,4.0,8.0,16,32]\n",
    "\n",
    "all_tr_losses = []\n",
    "all_te_losses = []\n",
    "all_acc_tr = []\n",
    "all_acc_te = []\n",
    "\n",
    "param_movement = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    def nn_wrapper(params, X):\n",
    "        return NN_func2(params, X.T, alpha=alpha, eps=0.25)\n",
    "    \n",
    "    ntk_fn = nt.empirical_ntk_fn(nn_wrapper, vmap_axes=0, trace_axes=())\n",
    "    K_0 = ntk_fn(Xt.T, None, params)\n",
    "    np.save(f\"kernels_alpha_sweep/k_0\", K_0)\n",
    "\n",
    "    opt_state = opt_init(params)\n",
    "    loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X, alpha) - y )**2 / alpha**2 ))\n",
    "    acc_fn = jit(lambda p, X, y: jnp.mean( ( y * NN_func2(p, X,alpha)) > 0.0 ))\n",
    "    reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "\n",
    "    grad_loss = jit(grad(reg_loss,0))\n",
    "\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    for t in range(60000):\n",
    "        opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "        if t % 2 == 0:\n",
    "            train_loss = alpha**2*loss_fn(get_params(opt_state), X, y)\n",
    "            test_loss = alpha**2*loss_fn(get_params(opt_state), Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            tr_acc += [ acc_fn(get_params(opt_state), X, y) ]\n",
    "            te_acc += [ acc_fn(get_params(opt_state), Xt, yt) ]\n",
    "            # sys.stdout.write(f'\\r t: {t} | train loss: {train_loss} | test loss: {test_loss}')\n",
    "        if t % 10000 == 0:\n",
    "            print(\" \")\n",
    "\n",
    "        if t % ntk_interval == 0:\n",
    "            K_test = ntk_fn(Xt.T, None, get_params(opt_state))\n",
    "            sys.stdout.write(f'\\r  t: {t} | train loss: {train_loss} | test loss: {test_loss} |frob ||kt-k0||_2: {frobenius(K_test-K_0)}')\n",
    "            # np.save(f\"kernels_alpha_sweep/k_{t}\", K_test) \n",
    "    all_tr_losses += [tr_losses]\n",
    "    all_te_losses += [te_losses]\n",
    "    all_acc_tr += [tr_acc]\n",
    "    all_acc_te += [te_acc]\n",
    "\n",
    "    paramsf = get_params(opt_state)\n",
    "    dparam = (jnp.sum((paramsf[0]-params[0])**2) + jnp.sum((paramsf[1]-params[1])**2)) / ( jnp.sum( params[0]**2 ) + jnp.sum(params[1]**2) )\n",
    "    param_movement += [  dparam ]\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure()\n",
    "for i,alpha in enumerate(alphas[:-1]):\n",
    "    print(alpha)\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses[i]),len(all_tr_losses[i])), \n",
    "        jnp.array(all_tr_losses[i]) / all_tr_losses[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses[i]),len(all_tr_losses[i])), \n",
    "        jnp.array(all_te_losses[i]) / all_te_losses[i][0], \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\alpha = 2^{%0.0f}$' % jnp.log2(alpha)\n",
    "    )\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'$t$',fontsize = 20)\n",
    "plt.ylabel('Loss',fontsize = 20)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c6f20-6dc0-48b0-9e77-fb052ef321f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Weight Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84395a76-cc41-47cb-a9e9-ab668ac15786",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_norms = [0.125,0.25,0.5,1.0,2.0]\n",
    "alpha = 1.0\n",
    "\n",
    "eta = 0.5 * N\n",
    "lamb = 0.0\n",
    "\n",
    "all_tr_losses_w = []\n",
    "all_te_losses_w = []\n",
    "all_acc_tr_w = []\n",
    "all_acc_te_w = []\n",
    "\n",
    "param_movement_w = []\n",
    "\n",
    "for i, wscale in enumerate(weight_norms):\n",
    "    a = wscale * random.normal(random.PRNGKey(0), (N, ))\n",
    "    W = wscale * random.normal(random.PRNGKey(0), (N, D))\n",
    "    params = [a, W]\n",
    "\n",
    "    opt_init, opt_update, get_params = optimizers.sgd( eta / wscale**2 )\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "\n",
    "    loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X,alpha)- NN_func2(params,X,alpha) - y )**2 / alpha**2 ))\n",
    "    acc_fn = jit(lambda p, X, y: jnp.mean( ( y * ( NN_func2(p, X,alpha)- NN_func2(params,X,alpha)) ) > 0.0 ))\n",
    "    reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "\n",
    "    grad_loss = jit(grad(reg_loss,0))\n",
    "\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    for t in range(50000):\n",
    "        opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            train_loss = alpha**2*loss_fn(get_params(opt_state), X, y)\n",
    "            test_loss = alpha**2*loss_fn(get_params(opt_state), Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            tr_acc += [ acc_fn(get_params(opt_state), X, y) ]\n",
    "            te_acc += [ acc_fn(get_params(opt_state), Xt, yt) ]\n",
    "            sys.stdout.write(f'\\r t: {t} | train loss: {train_loss} | test loss: {test_loss}')\n",
    "        if t % 10000 == 0:\n",
    "            print(\" \")\n",
    "\n",
    "    all_tr_losses_w += [tr_losses]\n",
    "    all_te_losses_w += [te_losses]\n",
    "    all_acc_tr_w += [tr_acc]\n",
    "    all_acc_te_w += [te_acc]\n",
    "\n",
    "    paramsf = get_params(opt_state)\n",
    "    dparam = (jnp.sum((paramsf[0]-params[0])**2) + jnp.sum((paramsf[1]-params[1])**2)) / ( jnp.sum(params[0]**2) + jnp.sum(params[1]**2) )\n",
    "    param_movement_w += [  dparam ]\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure()\n",
    "for i, wscale in enumerate(weight_norms):\n",
    "    print(alpha)\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_w[i]),len(all_tr_losses_w[i])), \n",
    "        jnp.array(all_tr_losses_w[i]) / all_tr_losses_w[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_w[i]),len(all_tr_losses_w[i])), \n",
    "        jnp.array(all_te_losses_w[i]) / all_te_losses_w[i][0],  \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\sigma = 2^{%0.0f}$' % jnp.log2(wscale)\n",
    "    )\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('t',fontsize = 20)\n",
    "plt.ylabel('Loss',fontsize = 20)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f1aff-3c95-41c2-b397-cd987e9b6f2f",
   "metadata": {},
   "source": [
    "# Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80637675-0de3-4705-bdec-1dc02c98437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "  t: 9900 | train loss: 0.0028801646549254656 | test loss: 0.07288174331188202 |frob ||kt-k0||_F: 0.08413097262382507 \n",
      "  t: 19900 | train loss: 0.0009458101121708751 | test loss: 0.030143799260258675 |frob ||kt-k0||_F: 0.08967255800962448 \n",
      "  t: 29900 | train loss: 0.0004962695529684424 | test loss: 0.017637422308325768 |frob ||kt-k0||_F: 0.09201108664274216 \n",
      "  t: 39900 | train loss: 0.00031404380570165813 | test loss: 0.011945870704948902 |frob ||kt-k0||_F: 0.09334668517112732 \n",
      "  t: 49900 | train loss: 0.00021996871510054916 | test loss: 0.008779174648225307 |frob ||kt-k0||_F: 0.09422557055950165 \n",
      "  t: 59900 | train loss: 0.00016424685600213706 | test loss: 0.006798961199820042 |frob ||kt-k0||_F: 0.094854153692722324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_188854/3767731452.py:86: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = 100\n",
    "P = 550\n",
    "N = 500\n",
    "ntk_interval = 100 \n",
    "\n",
    "X = random.normal(random.PRNGKey(0), (D,P))\n",
    "Xt = random.normal(random.PRNGKey(1), (D,1000))\n",
    "beta = random.normal(random.PRNGKey(2), (D,))\n",
    "\n",
    "y = target_fn(beta, X)\n",
    "yt = target_fn(beta, Xt)\n",
    "\n",
    "a = random.normal(random.PRNGKey(0), (N, ))\n",
    "W = random.normal(random.PRNGKey(0), (N, D))\n",
    "params = [a, W]\n",
    "\n",
    "alpha=1.0\n",
    "eta = 0.5 * N\n",
    "lamb = 0.0\n",
    "opt_init, opt_update, get_params = optimizers.sgd(eta)\n",
    "\n",
    "epsilons = [2**(-2)]#,2**(-1),1,2,4]\n",
    "\n",
    "all_tr_losses_eps = []\n",
    "all_te_losses_eps = []\n",
    "all_acc_tr_eps = []\n",
    "all_acc_te_eps = []\n",
    "\n",
    "param_movement = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    def nn_wrapper(params, X):\n",
    "        return NN_func2(params, X.T, alpha=alpha, eps=eps)\n",
    "    \n",
    "    ntk_fn = nt.empirical_ntk_fn(nn_wrapper, vmap_axes=0, trace_axes=())\n",
    "    K_0 = ntk_fn(Xt.T, None, params)\n",
    "    np.save(f\"kernels_eps_sweep/k_0\", K_0)\n",
    "\n",
    "    opt_state = opt_init(params)\n",
    "    loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X, alpha=alpha, eps=eps) - y )**2 / alpha**2 ))\n",
    "    acc_fn = jit(lambda p, X, y: jnp.mean( ( y * NN_func2(p, X, alpha=alpha, eps=eps)) > 0.0 ))\n",
    "    reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "\n",
    "    grad_loss = jit(grad(reg_loss,0))\n",
    "\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    for t in range(60000):\n",
    "        opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "        if t % 2 == 0:\n",
    "            train_loss = alpha**2*loss_fn(get_params(opt_state), X, y)\n",
    "            test_loss = alpha**2*loss_fn(get_params(opt_state), Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            tr_acc += [ acc_fn(get_params(opt_state), X, y) ]\n",
    "            te_acc += [ acc_fn(get_params(opt_state), Xt, yt) ]\n",
    "            # sys.stdout.write(f'\\r t: {t} | train loss: {train_loss} | test loss: {test_loss}')\n",
    "        if t % 10000 == 0:\n",
    "            print(\" \")\n",
    "\n",
    "        if t % ntk_interval == 0:\n",
    "            K_test = ntk_fn(Xt.T, None, get_params(opt_state))\n",
    "            sys.stdout.write(f'\\r  t: {t} | train loss: {train_loss} | test loss: {test_loss} |frob ||kt-k0||_F: {frobenius(K_test-K_0)}')\n",
    "            # np.save(f\"kernels_eps_sweep/k_{t}\", K_test) \n",
    "    all_tr_losses_eps += [tr_losses]\n",
    "    all_te_losses_eps += [te_losses]\n",
    "    all_acc_tr_eps += [tr_acc]\n",
    "    all_acc_te_eps += [te_acc]\n",
    "\n",
    "    paramsf = get_params(opt_state)\n",
    "    dparam = (jnp.sum((paramsf[0]-params[0])**2) + jnp.sum((paramsf[1]-params[1])**2)) / ( jnp.sum( params[0]**2 ) + jnp.sum(params[1]**2) )\n",
    "    param_movement += [dparam]\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure()\n",
    "for i, eps in enumerate(epsilons[:-1]):\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_eps[i]),len(all_tr_losses_eps[i])), \n",
    "        jnp.array(all_tr_losses_eps[i]) / all_tr_losses_eps[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_eps[i]),len(all_tr_losses_eps[i])), \n",
    "        jnp.array(all_te_losses_eps[i]) / all_te_losses_eps[i][0],  \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\alpha = 2^{%0.0f}$' % jnp.log2(alpha)\n",
    "    )\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'$t$',fontsize = 20)\n",
    "plt.ylabel('Loss',fontsize = 20)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1097040-0b3e-44cc-aa94-0a601b777abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
