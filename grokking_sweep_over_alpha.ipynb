{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfec7aa-f386-422e-a965-3f15aa2e3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neural_tangents as nt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, jit, jacfwd, jacrev, lax, random, vmap\n",
    "from jax.example_libraries import optimizers\n",
    "from neural_tangents import stax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c67464-d868-4ace-bfc2-fc6c52de9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps.get_cmap('tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc9299-fb90-43b4-97e4-2c24b36bcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(z, eps = 0.25):\n",
    "    return z + 0.5*eps*z**2\n",
    "\n",
    "def NN_func2(params, X, alpha, eps=0.25):\n",
    "    a, W = params\n",
    "\n",
    "    D = W.shape[1]\n",
    "    N = a.shape[0]\n",
    "\n",
    "    h = W @ X / jnp.sqrt(D)\n",
    "    f = alpha * jnp.mean( phi(h, eps = eps), axis = 0)\n",
    "    return f\n",
    "\n",
    "def target_fn(beta, X):\n",
    "    return (X.T @ beta / jnp.sqrt(D))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6b332-bb0a-46e3-b8f1-6ce921d93b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 100\n",
    "P = 550\n",
    "N = 500\n",
    "ntk_interval = 100 \n",
    "\n",
    "X = random.normal(random.PRNGKey(0), (D,P))\n",
    "Xt = random.normal(random.PRNGKey(1), (D,1000))\n",
    "beta = random.normal(random.PRNGKey(2), (D,))\n",
    "\n",
    "y = target_fn(beta, X)\n",
    "yt = target_fn(beta, Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00064ad-ea80-4448-9fc5-8a0af73c957e",
   "metadata": {},
   "source": [
    "# Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3165b9a-6354-4413-8695-53602c03e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = random.normal(random.PRNGKey(0), (N, ))\n",
    "W = random.normal(random.PRNGKey(0), (N, D))\n",
    "params = [a, W]\n",
    "\n",
    "eps = 0.25\n",
    "eta = 0.5 * N\n",
    "lamb = 0.0\n",
    "opt_init, opt_update, get_params = optimizers.sgd(eta)\n",
    "\n",
    "alphas = [2**(-5),0.25,0.5,1.0,2.0,4.0,8.0,16,32]\n",
    "\n",
    "all_tr_losses = []\n",
    "all_te_losses = []\n",
    "all_acc_tr = []\n",
    "all_acc_te = []\n",
    "\n",
    "param_movement = []\n",
    "for alpha in alphas:\n",
    "    def nn_wrapper(params, X):\n",
    "        return NN_func2(params, X.T, alpha=alpha, eps=0.25)\n",
    "\n",
    "    folder = f\"kernels_alpha_sweep/alpha_{alpha}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    ntk_fn = nt.empirical_ntk_fn(nn_wrapper, vmap_axes=0, trace_axes=())\n",
    "    K_0 = ntk_fn(Xt.T, None, params)\n",
    "    \n",
    "    np.save(os.path.join(folder, \"k_0\"), K_0)\n",
    "\n",
    "    opt_state = opt_init(params)\n",
    "    loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X, alpha) - y )**2 / alpha**2 ))\n",
    "    acc_fn = jit(lambda p, X, y: jnp.mean( ( y * NN_func2(p, X,alpha)) > 0.0 ))\n",
    "    reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "\n",
    "    grad_loss = jit(grad(reg_loss,0))\n",
    "\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    \n",
    "    for t in range(60000):\n",
    "        opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "        if t % 2 == 0:\n",
    "            train_loss = alpha**2*loss_fn(get_params(opt_state), X, y)\n",
    "            test_loss = alpha**2*loss_fn(get_params(opt_state), Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            tr_acc += [ acc_fn(get_params(opt_state), X, y) ]\n",
    "            te_acc += [ acc_fn(get_params(opt_state), Xt, yt) ]\n",
    "            # sys.stdout.write(f'\\r t: {t} | train loss: {train_loss} | test loss: {test_loss}')\n",
    "        if t % 10000 == 0:\n",
    "            print(\" \")\n",
    "\n",
    "        if t % ntk_interval == 0:\n",
    "            K_test = ntk_fn(Xt.T, None, get_params(opt_state))\n",
    "            sys.stdout.write(f'\\r  t: {t} | train loss: {train_loss} | test loss: {test_loss} |frob ||kt-k0||_2: {jnp.linalg.norm(K_test-K_0)}')\n",
    "            np.save(os.path.join(folder, f\"k_{t}\"), K_test) \n",
    "    all_tr_losses += [tr_losses]\n",
    "    all_te_losses += [te_losses]\n",
    "    all_acc_tr += [tr_acc]\n",
    "    all_acc_te += [te_acc]\n",
    "\n",
    "    paramsf = get_params(opt_state)\n",
    "    dparam = (jnp.sum((paramsf[0]-params[0])**2) + jnp.sum((paramsf[1]-params[1])**2)) / ( jnp.sum( params[0]**2 ) + jnp.sum(params[1]**2) )\n",
    "    param_movement += [  dparam ]\n",
    "\n",
    "    losses_folder = \"kernels_alpha_sweep\"\n",
    "    np.save(os.path.join(losses_folder, \"train_loss\"), all_tr_losses)\n",
    "    np.save(os.path.join(losses_folder, \"test_loss\"), all_te_losses)\n",
    "    np.save(os.path.join(losses_folder, \"train_accuracy\"), all_acc_tr)\n",
    "    np.save(os.path.join(losses_folder, \"test_accuracy\"), all_acc_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e311b0-ae04-4842-99f0-ae37823aa7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory before next exp\n",
    "del all_tr_losses\n",
    "del all_te_losses\n",
    "del all_acc_tr\n",
    "del all_acc_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c6f20-6dc0-48b0-9e77-fb052ef321f2",
   "metadata": {},
   "source": [
    "# Weight Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b9e85-2548-4d7e-8453-1a69e2d747ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_norms = [0.125,0.25,0.5,1.0,2.0]\n",
    "alpha = 1.0\n",
    "eps = 0.25\n",
    "eta = 0.5 * N\n",
    "lamb = 0.0\n",
    "\n",
    "all_tr_losses_w = []\n",
    "all_te_losses_w = []\n",
    "all_acc_tr_w = []\n",
    "all_acc_te_w = []\n",
    "\n",
    "param_movement_w = []\n",
    "\n",
    "for i, wscale in enumerate(weight_norms):\n",
    "    # setup wrapper and folder to save things\n",
    "    def nn_wrapper(params, X):\n",
    "        return NN_func2(params, X.T, alpha=alpha, eps=eps)\n",
    "    w_folder = f\"kernels_wnorm_sweep/{wscale}\"\n",
    "    os.makedirs(w_folder, exist_ok=True)\n",
    "\n",
    "    a = wscale * random.normal(random.PRNGKey(0), (N, ))\n",
    "    W = wscale * random.normal(random.PRNGKey(0), (N, D))\n",
    "    params = [a, W]\n",
    "\n",
    "    # save k_0 for reference\n",
    "    ntk_fn = nt.empirical_ntk_fn(nn_wrapper, vmap_axes=0, trace_axes=())\n",
    "    K_0 = ntk_fn(Xt.T, None, params)\n",
    "    np.save(os.path.join(w_folder, \"k_0\"), K_0)\n",
    "\n",
    "    opt_init, opt_update, get_params = optimizers.sgd( eta / wscale**2 )\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "\n",
    "    loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p,X,alpha)- NN_func2(params,X,alpha) - y )**2 / alpha**2 ))\n",
    "    acc_fn = jit(lambda p, X, y: jnp.mean( ( y * ( NN_func2(p, X,alpha)- NN_func2(params,X,alpha)) ) > 0.0 ))\n",
    "    reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "\n",
    "    grad_loss = jit(grad(reg_loss,0))\n",
    "\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    for t in range(50000):\n",
    "        opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            train_loss = alpha**2*loss_fn(get_params(opt_state), X, y)\n",
    "            test_loss = alpha**2*loss_fn(get_params(opt_state), Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            tr_acc += [ acc_fn(get_params(opt_state), X, y) ]\n",
    "            te_acc += [ acc_fn(get_params(opt_state), Xt, yt) ]\n",
    "            #sys.stdout.write(f'\\r t: {t} | train loss: {train_loss} | test loss: {test_loss}')\n",
    "        if t % 10000 == 0:\n",
    "            print(\" \")\n",
    "\n",
    "        if t % ntk_interval == 0:\n",
    "            K_test = ntk_fn(Xt.T, None, get_params(opt_state))\n",
    "            sys.stdout.write(f'\\r  t: {t} | train loss: {train_loss} | test loss: {test_loss} |frob ||kt-k0||_F: {frobenius(K_test-K_0)}')\n",
    "            np.save(os.path.join(w_folder, f\"k_{t}\"), K_test) \n",
    "\n",
    "    all_tr_losses_w += [tr_losses]\n",
    "    all_te_losses_w += [te_losses]\n",
    "    all_acc_tr_w += [tr_acc]\n",
    "    all_acc_te_w += [te_acc]\n",
    "\n",
    "    paramsf = get_params(opt_state)\n",
    "    dparam = (jnp.sum((paramsf[0]-params[0])**2) + jnp.sum((paramsf[1]-params[1])**2)) / ( jnp.sum(params[0]**2) + jnp.sum(params[1]**2) )\n",
    "    param_movement_w += [  dparam ]\n",
    "\n",
    "    loss_folder = \"kernels_wnorm_sweep\"\n",
    "    np.save(os.path.join(loss_folder, \"train_loss\"), all_tr_losses_w)\n",
    "    np.save(os.path.join(loss_folder, \"test_loss\"), all_te_losses_w)\n",
    "    np.save(os.path.join(loss_folder, \"train_accuracy\"), all_acc_tr_w)\n",
    "    np.save(os.path.join(loss_folder, \"test_accuracy\"), all_acc_te_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8e5c3-085d-490d-8dd6-6b1a200b34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory before next exp\n",
    "del all_tr_losses_w\n",
    "del all_te_losses_w\n",
    "del all_acc_tr_w\n",
    "del all_acc_te_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f1aff-3c95-41c2-b397-cd987e9b6f2f",
   "metadata": {},
   "source": [
    "# Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c5209-0068-4f8d-88db-0b59566be016",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 100\n",
    "P = 550\n",
    "N = 500\n",
    "ntk_interval = 100 \n",
    "\n",
    "X = random.normal(random.PRNGKey(0), (D,P))\n",
    "Xt = random.normal(random.PRNGKey(1), (D,1000))\n",
    "beta = random.normal(random.PRNGKey(2), (D,))\n",
    "\n",
    "y = target_fn(beta, X)\n",
    "yt = target_fn(beta, Xt)\n",
    "\n",
    "a = random.normal(random.PRNGKey(0), (N, ))\n",
    "W = random.normal(random.PRNGKey(0), (N, D))\n",
    "params = [a, W]\n",
    "\n",
    "alpha=1.0\n",
    "eta = 0.5 * N\n",
    "lamb = 0.0\n",
    "opt_init, opt_update, get_params = optimizers.sgd(eta)\n",
    "\n",
    "epsilons = [2**(-2),2**(-1),1,2,4]\n",
    "\n",
    "all_tr_losses_eps = []\n",
    "all_te_losses_eps = []\n",
    "all_acc_tr_eps = []\n",
    "all_acc_te_eps = []\n",
    "\n",
    "param_movement = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    def nn_wrapper(params, X):\n",
    "        return NN_func2(params, X.T, alpha=alpha, eps=eps)\n",
    "    eps_folder = f\"kernels_eps_sweep/{eps}\"\n",
    "    os.makedirs(eps_folder, exist_ok=True)\n",
    "    \n",
    "    ntk_fn = nt.empirical_ntk_fn(nn_wrapper, vmap_axes=0, trace_axes=())\n",
    "    K_0 = ntk_fn(Xt.T, None, params)\n",
    "    np.save(os.path.join(eps_folder, \"k_0\"), K_0)\n",
    "\n",
    "    opt_state = opt_init(params)\n",
    "    loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X, alpha=alpha, eps=eps) - y )**2 / alpha**2 ))\n",
    "    acc_fn = jit(lambda p, X, y: jnp.mean( ( y * NN_func2(p, X, alpha=alpha, eps=eps)) > 0.0 ))\n",
    "    reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "\n",
    "    grad_loss = jit(grad(reg_loss,0))\n",
    "\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    for t in range(60000):\n",
    "        opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "        if t % 2 == 0:\n",
    "            train_loss = alpha**2*loss_fn(get_params(opt_state), X, y)\n",
    "            test_loss = alpha**2*loss_fn(get_params(opt_state), Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            tr_acc += [ acc_fn(get_params(opt_state), X, y) ]\n",
    "            te_acc += [ acc_fn(get_params(opt_state), Xt, yt) ]\n",
    "            # sys.stdout.write(f'\\r t: {t} | train loss: {train_loss} | test loss: {test_loss}')\n",
    "        if t % 10000 == 0:\n",
    "            print(\" \")\n",
    "\n",
    "        if t % ntk_interval == 0:\n",
    "            K_test = ntk_fn(Xt.T, None, get_params(opt_state))\n",
    "            sys.stdout.write(f'\\r  t: {t} | train loss: {train_loss} | test loss: {test_loss} |frob ||kt-k0||_F: {frobenius(K_test-K_0)}')\n",
    "            np.save(os.path.join(eps_folder, f\"k_{t}\"), K_test) \n",
    "    all_tr_losses_eps += [tr_losses]\n",
    "    all_te_losses_eps += [te_losses]\n",
    "    all_acc_tr_eps += [tr_acc]\n",
    "    all_acc_te_eps += [te_acc]\n",
    "\n",
    "    paramsf = get_params(opt_state)\n",
    "    dparam = (jnp.sum((paramsf[0]-params[0])**2) + jnp.sum((paramsf[1]-params[1])**2)) / ( jnp.sum( params[0]**2 ) + jnp.sum(params[1]**2) )\n",
    "    param_movement += [dparam]\n",
    "\n",
    "    loss_folder = \"kernels_eps_sweep\"\n",
    "    np.save(os.path.join(loss_folder, \"train_loss\"), all_tr_losses_eps)\n",
    "    np.save(os.path.join(loss_folder, \"test_loss\"), all_te_losses_eps)\n",
    "    np.save(os.path.join(loss_folder, \"train_accuracy\"), all_acc_tr_eps)\n",
    "    np.save(os.path.join(loss_folder, \"test_accuracy\"), all_acc_te_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be29ce-4ebd-4627-a00f-ba7d1dff101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tr_losses_eps = np.load(os.path.join(eps_folder, \"train_loss\"))\n",
    "all_te_losses_eps = np.load(os.path.join(eps_folder, \"test_loss\"))\n",
    "all_acc_tr_losses_eps = np.load(os.path.join(eps_folder, \"train_accuracy\"))\n",
    "all_acc_te_losses_eps = np.load(os.path.join(eps_folder, \"test_accuracy\"))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure()\n",
    "for i, eps in enumerate(epsilons):\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_eps[i]),len(all_tr_losses_eps[i])), \n",
    "        jnp.array(all_tr_losses_eps[i]) / all_tr_losses_eps[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    plt.plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_eps[i]),len(all_tr_losses_eps[i])), \n",
    "        jnp.array(all_te_losses_eps[i]) / all_te_losses_eps[i][0],  \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\epsilon = 2^{%0.0f}$' % jnp.log2(eps)\n",
    "    )\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'$t$',fontsize = 20)\n",
    "plt.ylabel('Loss',fontsize = 20)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/eps_sweep.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1097040-0b3e-44cc-aa94-0a601b777abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory before next exp\n",
    "del all_tr_losses_eps\n",
    "del all_te_losses_eps\n",
    "del all_acc_tr_eps\n",
    "del all_acc_te_eps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
