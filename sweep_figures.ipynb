{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57545e57-2c2b-4f1f-810a-5ba906f9d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03b680-1b33-496a-ab9a-5b56f4a9657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b0a39-bcf1-4fef-b0b7-7f3cbbbeac4c",
   "metadata": {},
   "source": [
    "# Compute $K_{\\text{diff}}$ if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609aaf3-24dd-42af-973f-00b53e963ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"kernels_alpha_sweep/frob_k.npy\"):\n",
    "    alphas = [2**(-5),0.25,0.5,1.0,2.0,4.0,8.0,16,32]\n",
    "    alpha_frob = []\n",
    "    ntk_interval = 100\n",
    "    \n",
    "    for i, alpha in enumerate(alphas):\n",
    "        print(f\"Alpha = {alpha}\")\n",
    "        kernels_list = glob.glob(f\"kernels_alpha_sweep/alpha_{alpha}/k_*.npy\")\n",
    "        kernels_list.sort(key=natural_keys)\n",
    "        \n",
    "        k_0 = np.load(kernels_list[0])\n",
    "        k_test = kernels_list\n",
    "        t = [int(k.split(\"_\")[-1][:-4]) for k in kernels_list]\n",
    "        print(\"Calculating Frobenius norm\")\n",
    "        all_fb = []\n",
    "        for k in k_test:\n",
    "            k_t = np.load(k)\n",
    "            fb = jnp.linalg.norm(k_t-k_0)\n",
    "            all_fb.append(fb)\n",
    "    \n",
    "        print(\"Interpolating\")\n",
    "        # interpolate correct intervals to plot\n",
    "        t_values = np.arange(0, t[-1]+1, ntk_interval)\n",
    "        interpolator = interp1d(t_values, all_fb, kind='linear', fill_value='extrapolate')\n",
    "        interpolated_frob = interpolator(np.arange(max(t)))\n",
    "    \n",
    "        alpha_frob.append(interpolated_frob)\n",
    "    \n",
    "    np.save(\"kernels_alpha_sweep/frob_k.npy\", alpha_frob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b29fd-d747-4b99-92a6-fa3471d5577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"kernels_wnorm_sweep/frob_k.npy\"):\n",
    "    weight_norms = [0.125,0.25,0.5,1.0,2.0]\n",
    "    w_frob = []\n",
    "    ntk_interval = 100\n",
    "    w_frob = np.load(\"kernels_wnorm_sweep/frob_k.npy\")\n",
    "    \n",
    "    for i, wnorm in enumerate(weight_norms):\n",
    "        print(f\"Weigth = {wnorm}\")\n",
    "        kernels_list = glob.glob(f\"kernels_wnorm_sweep/{wnorm}/k_*.npy\")\n",
    "        kernels_list.sort(key=natural_keys)\n",
    "        \n",
    "        k_0 = np.load(kernels_list[0])\n",
    "        k_test = kernels_list\n",
    "        t = [int(k.split(\"_\")[-1][:-4]) for k in kernels_list]\n",
    "        print(\"Calculating Frobenius norm\")\n",
    "        all_fb = []\n",
    "        for k in k_test:\n",
    "            k_t = np.load(k)\n",
    "            fb = frobenius(k_t-k_0)\n",
    "            all_fb.append(fb)\n",
    "    \n",
    "        print(\"Interpolating\")\n",
    "        # interpolate correct intervals to plot\n",
    "        t_values = np.arange(0, t[-1]+1, ntk_interval)\n",
    "        interpolator = interp1d(t_values, all_fb, kind='linear', fill_value='extrapolate')\n",
    "        interpolated_frob = interpolator(np.arange(max(t)))\n",
    "    \n",
    "        w_frob.append(interpolated_frob)\n",
    "    \n",
    "    np.save(\"kernels_wnorm_sweep/frob_k.npy\", w_frob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c902457-0ebf-4304-b1bc-e18277d6079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"kernels_eps_sweep/frob_k.npy\"):\n",
    "    epsilons = [2**(-2),2**(-1),1,2,4]\n",
    "    eps_frob = []\n",
    "    ntk_interval = 100\n",
    "    \n",
    "    for i, eps in enumerate(epsilons):\n",
    "        print(f\"Eps = {eps}\")\n",
    "        kernels_list = glob.glob(f\"kernels_eps_sweep/{eps}/k_*.npy\")\n",
    "        kernels_list.sort(key=natural_keys)\n",
    "        \n",
    "        k_0 = np.load(kernels_list[0])\n",
    "        k_test = kernels_list\n",
    "        t = [int(k.split(\"_\")[-1][:-4]) for k in kernels_list]\n",
    "        print(\"Calculating Frobenius norm\")\n",
    "        all_fb = []\n",
    "        for k in k_test:\n",
    "            k_t = np.load(k)\n",
    "            fb = frobenius(k_t-k_0)\n",
    "            all_fb.append(fb)\n",
    "    \n",
    "        print(\"Interpolating\")\n",
    "        # interpolate correct intervals to plot\n",
    "        t_values = np.arange(0, t[-1]+1, ntk_interval)\n",
    "        interpolator = interp1d(t_values, all_fb, kind='linear', fill_value='extrapolate')\n",
    "        interpolated_frob = interpolator(np.arange(max(t)))\n",
    "    \n",
    "        eps_frob.append(interpolated_frob)\n",
    "    \n",
    "    np.save(\"kernels_eps_sweep/frob_k.npy\", eps_frob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071964f5-e534-4a08-92c2-30c3709c7eec",
   "metadata": {},
   "source": [
    "# Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab70b1-9d49-43ca-8e52-ee68d6a389f8",
   "metadata": {},
   "source": [
    "## Alpha Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b446b-e9c2-4194-88bc-a8f33e113eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f\"kernels_alpha_sweep\"\n",
    "all_tr_losses = np.load(os.path.join(folder, \"train_loss.npy\"))\n",
    "all_te_losses = np.load(os.path.join(folder, \"test_loss.npy\"))\n",
    "all_acc_tr_losses = np.load(os.path.join(folder, \"train_accuracy.npy\"))\n",
    "all_acc_te_losses = np.load(os.path.join(folder, \"test_accuracy.npy\"))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5), sharex=True)\n",
    "\n",
    "alphas = [2**(-5),0.25,0.5,1.0,2.0,4.0,8.0,16,32]\n",
    "for i, alpha in enumerate(alphas[:-1]):    \n",
    "    #print(alpha)\n",
    "    ax[0].plot(\n",
    "        jnp.linspace(1,len(all_tr_losses[i]),len(all_tr_losses[i])), \n",
    "        jnp.array(all_tr_losses[i]) / all_tr_losses[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    ax[0].plot(\n",
    "        jnp.linspace(1,len(all_tr_losses[i]),len(all_tr_losses[i])), \n",
    "        jnp.array(all_te_losses[i]) / all_te_losses[i][0], \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\alpha = 2^{%0.0f}$' % jnp.log2(alpha)\n",
    "    )\n",
    "\n",
    "    ax[1].plot(alpha_frob[i], label = r'$\\alpha = 2^{%0.0f}$' % jnp.log2(alpha))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel(r'$t$', fontsize=20)\n",
    "ax[0].set_ylabel('Loss', fontsize=20)\n",
    "ax[1].set_xlabel(r'$t$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$\\|K_t - K_0\\|_F$',fontsize = 20)\n",
    "ax[1].legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"figures/alpha_sweep.png\") #, bbox_inches=\"tight\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ef686-d25b-4b21-a8fd-f098e0fa793d",
   "metadata": {},
   "source": [
    "## Weight Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac23244-4c8d-46b0-a105-24c142a6905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_norms = [0.125,0.25,0.5,1.0,2.0]\n",
    "w_folder = \"kernels_wnorm_sweep\"\n",
    "\n",
    "all_tr_losses_w = np.load(os.path.join(w_folder, \"train_loss.npy\"))\n",
    "all_te_losses_w = np.load(os.path.join(w_folder, \"test_loss.npy\"))\n",
    "all_acc_tr_losses_w = np.load(os.path.join(w_folder, \"train_accuracy.npy\"))\n",
    "all_acc_te_losses_w = np.load(os.path.join(w_folder, \"test_accuracy.npy\"))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5),sharex=True)\n",
    "for i, wscale in enumerate(weight_norms):\n",
    "    print(wscale)\n",
    "    ax[0].plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_w[i]),len(all_tr_losses_w[i])), \n",
    "        jnp.array(all_tr_losses_w[i]) / all_tr_losses_w[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    ax[0].plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_w[i]),len(all_tr_losses_w[i])), \n",
    "        jnp.array(all_te_losses_w[i]) / all_te_losses_w[i][0],  \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\sigma = 2^{%0.0f}$' % jnp.log2(wscale)\n",
    "    )\n",
    "\n",
    "    ax[1].plot(w_frob[i], label = r'$\\sigma = 2^{%0.0f}$' % jnp.log2(wscale))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel(r'$t$', fontsize=20)\n",
    "ax[0].set_ylabel('Loss', fontsize=20)\n",
    "\n",
    "ax[1].set_xlabel(r'$t$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$\\|K_t - K_0\\|_F$',fontsize = 20)\n",
    "ax[1].legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/weightnorm_sweep.png\") #, bbox_inches=\"tight\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f04b9c-6d09-4b9d-b10b-3e666a9245ae",
   "metadata": {},
   "source": [
    "## Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a785a-9887-4a7a-ba30-22dc1be6e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [2**(-2),2**(-1),1,2,4]\n",
    "eps_folder = \"kernels_eps_sweep\"\n",
    "all_tr_losses_eps = np.load(os.path.join(eps_folder, \"train_loss.npy\"))\n",
    "all_te_losses_eps = np.load(os.path.join(eps_folder, \"test_loss.npy\"))\n",
    "all_acc_tr_losses_eps = np.load(os.path.join(eps_folder, \"train_accuracy.npy\"))\n",
    "all_acc_te_losses_eps = np.load(os.path.join(eps_folder, \"test_accuracy.npy\"))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5),sharex=True)\n",
    "for i, eps in enumerate(epsilons):\n",
    "    ax[0].plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_eps[i]),len(all_tr_losses_eps[i])), \n",
    "        jnp.array(all_tr_losses_eps[i]) / all_tr_losses_eps[i][0], \n",
    "        '--',  \n",
    "        color = f'C{i}'\n",
    "    )\n",
    "    ax[0].plot(\n",
    "        jnp.linspace(1,len(all_tr_losses_eps[i]),len(all_tr_losses_eps[i])), \n",
    "        jnp.array(all_te_losses_eps[i]) / all_te_losses_eps[i][0],  \n",
    "        color = f'C{i}', \n",
    "        label = r'$\\epsilon = 2^{%0.0f}$' % jnp.log2(eps)\n",
    "    )\n",
    "\n",
    "    ax[1].plot(eps_frob[i], label = r'$\\epsilon = 2^{%0.0f}$' % jnp.log2(eps))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel(r'$t$', fontsize=20)\n",
    "ax[0].set_ylabel('Loss', fontsize=20)\n",
    "ax[1].set_xlabel(r'$t$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$\\|K_t - K_0\\|_F$',fontsize = 20)\n",
    "ax[1].legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/eps_sweep.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
