{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bdc932-6bc7-4adc-92a1-b3e0a1525948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neural_tangents as nt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, jit, jacfwd, jacrev, lax, random, vmap\n",
    "from jax.example_libraries import optimizers\n",
    "from neural_tangents import stax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a2e6c-0cf3-4219-a7a3-f769a577046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps.get_cmap('tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea63845-1c95-4e6b-82d6-fd7ca1df6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 100\n",
    "P = 550\n",
    "N = 500\n",
    "\n",
    "def target_fn(beta, X):\n",
    "        return (X.T @ beta)**2/2.0\n",
    "\n",
    "X = random.normal(random.PRNGKey(0), (D,P))/ jnp.sqrt(D)\n",
    "Xt = random.normal(random.PRNGKey(1), (D,1000))/ jnp.sqrt(D)\n",
    "beta = random.normal(random.PRNGKey(2), (D,))\n",
    "\n",
    "y = target_fn(beta, X)\n",
    "yt = target_fn(beta,Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3ca4f-bd00-41a2-8930-777d116d39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(Xt.shape, yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea2434-3869-4442-9d3e-7006a7a04b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = random.normal(random.PRNGKey(0), (N, D))\n",
    "a = random.normal(random.PRNGKey(0), (N, ))\n",
    "params = [a, W]\n",
    "alpha = 1 # scaling parameter, NOT weight norm scale\n",
    "eps = 0.02\n",
    "\n",
    "def NN_func2(params,X):\n",
    "    global alpha\n",
    "    global eps\n",
    "\n",
    "    a, W = params\n",
    "    D = W.shape[1]\n",
    "    N = a.shape[0]\n",
    "    h = W @ X.T\n",
    "\n",
    "    f = alpha * np.mean(phi(h,eps),axis=0) # w/o readouts\n",
    "    return f\n",
    "\n",
    "\n",
    "def phi(z, eps = 0.25):\n",
    "        return z + 0.5*eps*z**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb82d9-6156-415e-aee6-ab59e912d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = random.normal(random.PRNGKey(0), (N, D))\n",
    "a = random.normal(random.PRNGKey(0), (N, ))\n",
    "params = [a, W]\n",
    "alpha = 1 # scaling parameter, NOT weight norm scale\n",
    "eps = 0.02\n",
    "\n",
    "def NN_func2(params,X):\n",
    "    global alpha\n",
    "    global eps\n",
    "\n",
    "    a, W = params\n",
    "    D = W.shape[1]\n",
    "    N = a.shape[0]\n",
    "    h = W @ X.T\n",
    "\n",
    "    f = alpha * np.mean(phi(h,eps),axis=0) # w/o readouts\n",
    "    return f\n",
    "\n",
    "\n",
    "def phi(z, eps = 0.25):\n",
    "        return z + 0.5*eps*z**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa34c6-af93-4402-9aa1-579e77326b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk_fn = nt.empirical_ntk_fn(\n",
    "    NN_func2, vmap_axes=0, trace_axes=())\n",
    "#, implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES)\n",
    "\n",
    "def kernel_regression(X, y, Xt, yt, params, which='test'):\n",
    "      K_train = ntk_fn(X.T, None, params)\n",
    "\n",
    "      a = jnp.linalg.solve(K_train, y)\n",
    "\n",
    "      def estimate(xt):\n",
    "        k_test_train = ntk_fn(Xt.T, X.T, params)\n",
    "        k_test_train_squeezed = jnp.squeeze(k_test_train)\n",
    "        return jnp.dot(k_test_train_squeezed, a)\n",
    "\n",
    "      estimates = vmap(estimate)(Xt.T if which=='test' else X.T)\n",
    "      labels = yt if which=='test' else y\n",
    "      mse = jnp.mean((estimates - labels) ** 2)\n",
    "      return mse\n",
    "\n",
    "\n",
    "def kalignment(K, train_y):\n",
    "    train_yc = train_y.reshape(-1, 1)\n",
    "    train_yc = train_yc - train_yc.mean(axis=0)\n",
    "    Kc = K - K.mean(axis=0)\n",
    "    top = jnp.dot(jnp.dot(train_yc.T, Kc), train_yc)\n",
    "    bottom = jnp.linalg.norm(Kc) * (jnp.linalg.norm(train_yc)**2)\n",
    "    return jnp.trace(top)/bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900c8b0-a2a0-4615-a51a-db28612edc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmse = kernel_regression(X, y, Xt, yt, params)\n",
    "\n",
    "alphas = [1]\n",
    "epsilons = [0.02]\n",
    "epochs = 100000\n",
    "CENTER_LOSS = True\n",
    "TRAIN_READOUTS = False\n",
    "ntk_interval = 100\n",
    "\n",
    "for alpha in alphas:\n",
    "    for eps in epsilons:\n",
    "        kaligns_test = []\n",
    "        epochs_to_plot = []\n",
    "        dots = []\n",
    "        \n",
    "        Cs, As = [], []\n",
    "        actual_w1aligns, actual_w2aligns = [], []\n",
    "        w1_aligns, w2_aligns = [], []\n",
    "        w1_vars, w2_vars, ws_covs = [], [], []\n",
    "        vars_compute_interval = 50\n",
    "        \n",
    "        lamb = 0\n",
    "        eta = N/alpha**2\n",
    "        opt_init, opt_update, get_params = optimizers.sgd(eta)\n",
    "        opt_init_lin, opt_update_lin, get_params_lin = optimizers.sgd(eta)\n",
    "        \n",
    "        opt_state = opt_init(params)\n",
    "        opt_state_lin = opt_init_lin(params)\n",
    "        \n",
    "        f_lin = nt.linearize(NN_func2, params)\n",
    "        lin_tr_losses = []\n",
    "        lin_te_losses = []\n",
    "        \n",
    "        \n",
    "        if CENTER_LOSS:\n",
    "            loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X.T)- NN_func2(params,X.T) - y )**2))\n",
    "        else:\n",
    "            loss_fn = jit(lambda p, X, y: jnp.mean( ( NN_func2(p, X) - y )**2 / alpha**2 ))\n",
    "        \n",
    "        f_lin0 = nt.linearize(NN_func2, params)\n",
    "        lin_loss = jit(lambda p, X, y: jnp.mean((f_lin(p, X.T) - f_lin0(params, X.T) - y)**2)  )\n",
    "        grad_loss_lin = jit(grad(lin_loss, 0))\n",
    "        \n",
    "        reg_loss = jit(lambda p, X, y: loss_fn(p,X,y) + lamb / alpha * optimizers.l2_norm(p)**2 )\n",
    "        \n",
    "        grad_loss = jit(grad(reg_loss,0))\n",
    "        \n",
    "        tr_losses = []\n",
    "        te_losses = []\n",
    "        # check this\n",
    "        W_all = []\n",
    "        \n",
    "        alignments, alignmentst = [], []\n",
    "        epochs_to_plot = []\n",
    "        \n",
    "        t1s, t2s, t3s, epochs_to_compute = [], [], [], []\n",
    "        t1sm, t2sm, t3sm, ts_summ = [], [], [], []\n",
    "        ts_sum = []\n",
    "        alignments, alignmentst = [], []\n",
    "        \n",
    "        kmse = kernel_regression(X, y, Xt, yt, get_params(opt_state))\n",
    "        \n",
    "        for t in tqdm(range(epochs)):\n",
    "            opt_state = opt_update(t, grad_loss(get_params(opt_state), X, y), opt_state)\n",
    "            pars = get_params(opt_state)\n",
    "            \n",
    "            train_loss = loss_fn(pars, X, y)\n",
    "            test_loss = loss_fn(pars, Xt, yt)\n",
    "            tr_losses += [train_loss]\n",
    "            te_losses += [test_loss]\n",
    "            if t % 10000 == 0:\n",
    "                W_all.append(pars[1])\n",
    "            \n",
    "            # new update rule for f_lin to compare learning curves\n",
    "            lin_pars = get_params_lin(opt_state_lin)\n",
    "            opt_state_lin = opt_update_lin(t, grad_loss_lin(lin_pars, X, y), opt_state_lin)\n",
    "            \n",
    "            lin_tr_losses += [ lin_loss(lin_pars, X, y) ]\n",
    "            lin_te_losses += [ lin_loss(lin_pars, Xt, yt) ]\n",
    "        \n",
    "            if t % vars_compute_interval == 0:\n",
    "                epochs_to_compute.append(t)\n",
    "            if t % ntk_interval == 0 and t>0:\n",
    "                K_test = ntk_fn(Xt.T, None, pars)\n",
    "                cka_test = kalignment(K_test, yt)\n",
    "                kaligns_test += [ cka_test ]\n",
    "            \n",
    "            \n",
    "            if t % 5000 == 0 and t>0:\n",
    "                max_t = t\n",
    "                t_values = np.arange(0, max_t, ntk_interval)\n",
    "                interpolator = interp1d(t_values, kaligns_test, kind='linear', fill_value='extrapolate')\n",
    "                interpolated_kaligns = interpolator(np.arange(max_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0cec7-16c8-430e-87c9-4f49e7bba519",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(W_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b4dc2-4ee5-4502-a35b-b2acf593dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da082a-f28c-47a2-995b-3770fb4c26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "col = cmap(0)\n",
    "ax1.plot(np.array(tr_losses), linestyle='--', label=rf'Train Loss', color=col, lw=2)\n",
    "ax1.plot(np.array(te_losses), label=rf'Test Loss', color=col, lw=2)\n",
    "ax1.plot(np.array(lin_tr_losses), color='black', linestyle='--', label=f'Linearized train loss')\n",
    "ax1.plot(np.array(lin_te_losses), color='black', label=f'Linearized test loss')\n",
    "ax1.axhline(kmse, color='r', label=rf'$K_0$ regression MSE')\n",
    "ax1.set_xlabel('Epochs', fontsize=20)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('MSE', fontsize=20)\n",
    "ax1.legend(loc='lower left', bbox_to_anchor=(0, 0.1))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(interpolated_kaligns, linestyle='--', color='green', label=r'NTK alignment, $\\frac{y^T K_0y}{||K_0||_F||y||^2}$', lw=2)\n",
    "ax2.legend(loc='upper left', bbox_to_anchor=(0, 0.58))\n",
    "ax2.set_ylabel('NTK alignment', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b031e-0899-4f81-a17e-55818f0a0722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
